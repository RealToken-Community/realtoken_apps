const { Pool } = require('pg');

// === CONFIGURATION ===
const GRAPHQL_ENDPOINT = "https://gateway-arbitrum.network.thegraph.com/api/ae36a6bfa6af7dfa3487d2cecf583ebe/subgraphs/id/FPPoFB7S2dcCNrRyjM5QbaMwKqRZPdbTg8ysBrwXd4SP";

// Configuration des tailles de lots
const WALLET_BATCH_SIZE = 50; // Traiter 50 wallets √† la fois
const TOKEN_BATCH_SIZE = 100;  // Traiter 100 tokens √† la fois

// Configuration PostgreSQL
const pool = new Pool({
  host: 'postgres',
  database: 'realtoken',
  user: 'nocodb',
  password: 'nocodbpassword',
  port: 5432,
});

const query = `
query GetTransferEvents($tokenAddresses: [String!], $destinations: [String!], $skip: Int!) {
  transferEvents(
    where: { token_in: $tokenAddresses, destination_in: $destinations }
    orderBy: timestamp
    orderDirection: desc
    first: 1000
    skip: $skip
  ) {
    id token { id } amount sender destination timestamp transaction { id }
  }
}`;

// Fonction utilitaire pour diviser un array en chunks
function chunkArray(array, chunkSize) {
  const chunks = [];
  for (let i = 0; i < array.length; i += chunkSize) {
    chunks.push(array.slice(i, i + chunkSize));
  }
  return chunks;
}

async function getWalletsAndTokens() {
  try {
    console.log("üì§ R√©cup√©ration des wallets et tokens depuis PostgreSQL...");
    const client = await pool.connect();
    try {
      const [walletsResult, tokensResult] = await Promise.all([
        client.query('SELECT address FROM address_list'),
        client.query('SELECT "uuid" FROM real_tokens')
      ]);

      const destinations = walletsResult.rows
        .map(rec => rec.address?.toLowerCase())
        .filter(Boolean);
      const tokenAddresses = tokensResult.rows
        .map(rec => rec.uuid?.toLowerCase())
        .filter(Boolean);

      console.log(`‚úÖ ${destinations.length} wallets et ${tokenAddresses.length} tokens r√©cup√©r√©s.`);
      return { destinations, tokenAddresses };
    } finally {
      client.release();
    }
  } catch (err) {
    console.error("‚ùå Erreur lors de la r√©cup√©ration des wallets/tokens:", err.message);
    console.error("‚ùå Stack trace:", err.stack);
    return { destinations: [], tokenAddresses: [] };
  }
}

async function fetchTransactions(tokenAddresses, destinations, skip = 0) {
  try {
    const variables = { tokenAddresses, destinations, skip };
    const response = await fetch(GRAPHQL_ENDPOINT, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ query, variables })
    });
    if (!response.ok) throw new Error(`GraphQL query failed`);
    
    const data = await response.json();
    return data.data.transferEvents;
  } catch (err) {
    console.error("‚ùå Erreur lors de la r√©cup√©ration des transactions:", err.message);
    return [];
  }
}

async function fetchTransactionsForBatch(tokenBatch, destinationBatch) {
  console.log(`üîÑ Traitement du lot: ${tokenBatch.length} tokens √ó ${destinationBatch.length} wallets`);
  
  let allTransactions = [], skip = 0, fetched;
  do {
    const transactions = await fetchTransactions(tokenBatch, destinationBatch, skip);
    fetched = transactions.length;
    allTransactions = allTransactions.concat(transactions);
    skip += 1000;
    
    if (fetched === 1000) {
      console.log(`  üìÑ Page r√©cup√©r√©e: ${skip - 1000 + 1}-${skip} (${fetched} transactions)`);
    } else if (fetched > 0) {
      console.log(`  üìÑ Derni√®re page: ${skip - 1000 + 1}-${skip - 1000 + fetched} (${fetched} transactions)`);
    }
  } while (fetched === 1000);

  console.log(`  ‚úÖ Lot termin√©: ${allTransactions.length} transactions r√©cup√©r√©es`);
  return allTransactions;
}

async function getExistingTransactionIds() {
  const existingIds = new Set();

  console.log("üì§ R√©cup√©ration des transactions existantes depuis PostgreSQL...");
  try {
    const client = await pool.connect();
    try {
      const result = await client.query('SELECT "Transaction ID" FROM transactions_history');
      
      result.rows.forEach(rec => {
        if (rec["Transaction ID"]) {
          existingIds.add(rec["Transaction ID"].toLowerCase().trim());
        }
      });
    } finally {
      client.release();
    }
  } catch (err) {
    console.error(`‚ùå Erreur dans getExistingTransactionIds: ${err.message}`);
  }

  console.log(`‚úÖ ${existingIds.size} transactions d√©j√† stock√©es.`);
  return existingIds;
}

async function storeTransactions(records) {
  if (records.length === 0) {
    console.log("üöÄ Aucune nouvelle transaction √† stocker.");
    return;
  }

  // D√©doublonner les records au cas o√π il y aurait des doublons dans les donn√©es
  const uniqueRecords = [];
  const seenIds = new Set();
  
  for (const record of records) {
    if (!seenIds.has(record.transactionId)) {
      seenIds.add(record.transactionId);
      uniqueRecords.push(record);
    }
  }

  if (uniqueRecords.length < records.length) {
    console.log(`‚ö†Ô∏è ${records.length - uniqueRecords.length} doublons d√©tect√©s et supprim√©s dans les nouvelles donn√©es`);
  }

  try {
    const client = await pool.connect();
    try {
      // Compter les transactions existantes avant insertion
      const countBefore = await client.query(`
        SELECT COUNT(*) as count FROM transactions_history
      `);

      // Cr√©ation d'une table temporaire pour le batch insert
      await client.query(`
        CREATE TEMP TABLE temp_transactions (
          \"Transaction ID\" VARCHAR(255),
          \"Token ID\" VARCHAR(255),
          amount DECIMAL(20,4),
          sender VARCHAR(255),
          destination VARCHAR(255),
          timestamp VARCHAR(255),
          \"Transaction Hash\" VARCHAR(255)
        )
      `);

      // Insertion des donn√©es dans la table temporaire
      for (const record of uniqueRecords) {
        await client.query(`
          INSERT INTO temp_transactions (
            \"Transaction ID\", \"Token ID\", amount, sender, destination,
            timestamp, \"Transaction Hash\"
          ) VALUES ($1, $2, $3, $4, $5, $6, $7)
        `, [
          record.transactionId,
          record.tokenId,
          record.amount,
          record.sender,
          record.destination,
          record.timestamp,
          record.transactionHash
        ]);
      }

      // Insertion des donn√©es de la table temporaire vers la table principale
      // Utilise ON CONFLICT pour √©viter les erreurs de doublons
      await client.query(`
        INSERT INTO transactions_history (
          \"Transaction ID\", \"Token ID\", amount, sender, destination,
          timestamp, \"Transaction Hash\"
        )
        SELECT * FROM temp_transactions
        ON CONFLICT (\"Transaction ID\") DO NOTHING
      `);

      // Compter les transactions apr√®s insertion pour voir combien ont √©t√© r√©ellement ajout√©es
      const countAfter = await client.query(`
        SELECT COUNT(*) as count FROM transactions_history
      `);

      const actuallyInserted = parseInt(countAfter.rows[0].count) - parseInt(countBefore.rows[0].count);
      const duplicatesSkipped = uniqueRecords.length - actuallyInserted;

      console.log(`‚úÖ ${actuallyInserted} nouvelles transactions ajout√©es`);
      if (duplicatesSkipped > 0) {
        console.log(`‚ö†Ô∏è ${duplicatesSkipped} transactions ignor√©es (d√©j√† existantes)`);
      }
    } finally {
      client.release();
    }
  } catch (err) {
    console.error("‚ùå Erreur lors du stockage des transactions:", err.message);
  }
}

async function main() {
  try {
    console.log("üöÄ D√©marrage du script...");
    const { destinations, tokenAddresses } = await getWalletsAndTokens();
    if (!destinations.length || !tokenAddresses.length) {
      console.warn("‚ö†Ô∏è Aucun wallet ou token trouv√©, arr√™t du script.");
      return;
    }

    // Diviser en lots
    const tokenBatches = chunkArray(tokenAddresses, TOKEN_BATCH_SIZE);
    const destinationBatches = chunkArray(destinations, WALLET_BATCH_SIZE);
    
    console.log(`üìä Traitement par lots: ${tokenBatches.length} lots de tokens √ó ${destinationBatches.length} lots de wallets = ${tokenBatches.length * destinationBatches.length} requ√™tes`);

    const existingIds = await getExistingTransactionIds();
    let allNewRecords = [];
    let batchCount = 0;
    const totalBatches = tokenBatches.length * destinationBatches.length;

    // Traiter chaque combinaison de lots
    for (const tokenBatch of tokenBatches) {
      for (const destinationBatch of destinationBatches) {
        batchCount++;
        console.log(`\nüîÑ Traitement du lot ${batchCount}/${totalBatches}`);
        
        const transactions = await fetchTransactionsForBatch(tokenBatch, destinationBatch);
        
        // Filtrer les nouvelles transactions pour ce lot
        const newRecords = transactions
          .filter(tx => !existingIds.has(tx.id.toLowerCase()))
          .map(tx => ({
            transactionId: tx.id,
            tokenId: tx.token.id,
            amount: tx.amount,
            sender: tx.sender,
            destination: tx.destination,
            timestamp: tx.timestamp,
            transactionHash: tx.transaction.id
          }));

        allNewRecords = allNewRecords.concat(newRecords);
        console.log(`  üîç ${newRecords.length} nouvelles transactions dans ce lot`);
        
        // Petite pause entre les lots pour √©viter de surcharger l'API
        if (batchCount < totalBatches) {
          await new Promise(resolve => setTimeout(resolve, 100));
        }
      }
    }

    console.log(`\nüì¶ Total: ${allNewRecords.length} nouvelles transactions √† ins√©rer`);
    await storeTransactions(allNewRecords);
  } catch (err) {
    console.error("‚ùå Erreur dans le script:", err.message);
  } finally {
    await pool.end();
  }
}

main(); 